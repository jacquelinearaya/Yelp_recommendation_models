{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "One-click evaluation (final pipeline).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRlU7B1GDat3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import required packages:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files, drive\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ0Duz5oDeAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect to Google Drive (to load raw data)\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI2gthj4HSKm",
        "colab_type": "text"
      },
      "source": [
        "## Define Required Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEDT-ADGHUqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ranking(train_set, prediction_set):\n",
        "  \"\"\"\n",
        "  Input: train set must have these 5 columns: 'review_id,''user_id','business_id','rating','date'\n",
        "         prediction_set must have these 6 columns: 'review_id,,'user_id','business_id','rating','date' ,'prediction'\n",
        "\n",
        "  Output: a dataframe of 10 columns:'review_id, 'user_id','business_id','rating','date' ,'prediction', prediction2, true_rank, pred_rank, number_reviews\n",
        "  \"\"\"\n",
        "  #concat train and last_review dataframes\n",
        "  train_set = train_set.append(prediction_set[['review_id','user_id','business_id','rating' ,'prediction']].copy(), sort=True)\n",
        "\n",
        "  #create prediction2 column\n",
        "  train_set['prediction2'] = np.where(train_set['prediction'].notna(), train_set['prediction'], train_set['rating'])\n",
        "\n",
        "  #now by user, build user's ranking\n",
        "  grouped = train_set.groupby(\"user_id\")\n",
        "  train_set['true_rank'] = grouped['rating'].rank(method='average')\n",
        "  train_set['pred_rank'] = grouped['prediction2'].rank(method='average')\n",
        "  train_set['number_reviews'] = grouped['rating'].transform('count')\n",
        "\n",
        "  #return \n",
        "  ##keep only predictions ranking\n",
        "  pred_ranking = train_set[train_set.prediction.notna()]\n",
        "\n",
        "  return pred_ranking\n",
        "\n",
        "def coverage(train_set, prediction_set):\n",
        "  \"\"\"\n",
        "  Input:train set must have these 4 columns: 'user_id','business_id','rating','date'\n",
        "        prediction_set must have these 5 columns: 'user_id','business_id','rating','date' ,'prediction'\n",
        "\n",
        "  Output: -Ranking Dataframe (same from 'ranking' function) with an extra column named 'Coverage' indicating wheter the predictions from prediction set\n",
        "          are part of the coverage or not.\n",
        "  \"\"\"\n",
        "  model_ranking = ranking(train_set, prediction_set) #ranking function\n",
        "  diff = (model_ranking['true_rank'] - model_ranking['pred_rank'])/model_ranking['number_reviews']\n",
        "\n",
        "  model_ranking['coverage'] = np.where(np.abs(diff)<0.25, 1.0,0.0)  #1: good recom. 0: bad recom.\n",
        "  global_coverage = np.round(model_ranking.coverage.agg(sum)/model_ranking.user_id.size, 4)\n",
        "  \n",
        "  #return dataframe and global user coverage value\n",
        "  return (model_ranking, global_coverage*100)\n",
        "\n",
        "def csv_loader(csv_key, csv_value, dict_of_df):\n",
        "  csv_name = csv_key + '.csv'\n",
        "  downloaded = drive.CreateFile({'id': csv_value})\n",
        "  downloaded.GetContentFile(csv_name)\n",
        "  dict_of_df[csv_key] = pd.read_csv(csv_name, low_memory=False)\n",
        "  print(\"Downloaded: \", csv_key)\n",
        "\n",
        "def upload_csv_to_drive(destination_folder, dataframe, csv_filename):\n",
        "  dataframe.to_csv(csv_filename, index=False)\n",
        "  tmp = drive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": destination_folder}]})\n",
        "  tmp.SetContentFile(csv_filename)\n",
        "  tmp.Upload()\n",
        "  print(\"Upload complete for: \", csv_filename)\n",
        "\n",
        "# TODO: Create wrapper for methods where you calculate metrics by a DIMENSION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzMOXmhvENyX",
        "colab_type": "text"
      },
      "source": [
        "## Import All CSVs\n",
        "1.  Test CSVs (the test results of each of your models)\n",
        "2.  Two additional CSVs used for computing metics (training data and 'categorization')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIjBerEu-8V6",
        "colab_type": "code",
        "outputId": "9f370217-bf9d-4d54-9499-92b7cdc191af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# 1) Test data\n",
        "test_csv_files = {\n",
        "  'bias_baseline': '1whL3GlNUTGmvJSqgBcftgLro_Iyc4OMX',\n",
        "  'cf_baseline': '1yx7CbvemO_KRIXJKrF0gV4ryWhZlws4G',\n",
        "  'deep_learning': '17ncEfcXPV3srLyulf9lfwvvMyJ_ptjIz',\n",
        "}\n",
        "\n",
        "dataframes = {}\n",
        "for key, value in test_csv_files.items():\n",
        "  csv_loader(key, value, dataframes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded:  bias_baseline\n",
            "Downloaded:  cf_baseline\n",
            "Downloaded:  deep_learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KNGgby6LCm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quick debugging: new input CSVs (e.g. bias_baseline) have an additional\n",
        "# column, which was causing problems. Drop it for the time being.\n",
        "dataframes['bias_baseline'] = dataframes['bias_baseline'].drop(['rating'], axis = 1)\n",
        "dataframes['deep_learning'] = dataframes['deep_learning'].drop(['rating'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDjt35uqNiiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep learning is actually 4 models. Split these into 4 Dataframes:\n",
        "dataframes['deep_learning_m1f1'] = dataframes['deep_learning'][['review_id','user_id','business_id','prediction_m1f1']].rename(columns={'prediction_m1f1':'prediction'})\n",
        "dataframes['deep_learning_m1f2'] = dataframes['deep_learning'][['review_id','user_id','business_id','prediction_m1f2']].rename(columns={'prediction_m1f2':'prediction'})\n",
        "dataframes['deep_learning_m2f1'] = dataframes['deep_learning'][['review_id','user_id','business_id','prediction_m2f1']].rename(columns={'prediction_m2f1':'prediction'})\n",
        "dataframes['deep_learning_m2f2'] = dataframes['deep_learning'][['review_id','user_id','business_id','prediction_m2f2']].rename(columns={'prediction_m2f2':'prediction'})\n",
        "del dataframes['deep_learning']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYPbIiBSZ47k",
        "colab_type": "code",
        "outputId": "de283b7c-5c28-4160-d9b4-2d0a0251a726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 2) Metadata\n",
        "metadata_files = {\n",
        "  # 'train_set_new_og': '1-1vfc5jxrCggpVYDkf8Z2rVLjIIOh6bu',\n",
        "  'categorization': '1sBtQbasU-skHl2SZHI_qUi-Lf4Co1us5',\n",
        "  'train_set_new': '1u-6hcK4B0EncGsu0dKmS9Uc3eykS2Ref',\n",
        "}\n",
        "\n",
        "metadata = {}\n",
        "for key, value in metadata_files.items():\n",
        "  csv_loader(key, value, metadata)\n",
        "\n",
        "train_full = metadata['train_set_new']\n",
        "categorization = metadata['categorization'].drop(['user_id', 'business_id'], axis=1).rename(columns={'stars': 'rating'})"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloaded:  categorization\n",
            "Downloaded:  train_set_new\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOeb5EQoS-JO",
        "colab_type": "text"
      },
      "source": [
        "## Build Table 1 for final report \n",
        "##### You can find it here: https://drive.google.com/drive/u/2/folders/12pKbs8ptxpPaqaMmArivSqXQ58uv3iV0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft_09ke0Dprn",
        "colab_type": "code",
        "outputId": "c7547abf-0d25-4a05-a0b6-25657fedff73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# This loop will calculate all metrics for all models and save it to a dataframe:\n",
        "\n",
        "model_list, rmse_list, coverage_list = [], [], []\n",
        "\n",
        "for row in dataframes:\n",
        "  print(\"Working on\", row)\n",
        "  model_list.append(row)\n",
        "  \n",
        "  # Get the necessary DFs: \n",
        "    # 1) test results (test_df), \n",
        "    # 2) augmented test results with actual ratings and categories (test_df_cat), \n",
        "  test_df = dataframes[row]\n",
        "  test_df_cat = pd.merge(test_df, categorization, on='review_id', how='inner')\n",
        "  \n",
        "  # Compute RMSE:\n",
        "  test_df_cat['squared_error'] = (test_df_cat['rating'] - test_df_cat['prediction'])**2\n",
        "  model_rmse = np.sqrt(test_df_cat['squared_error'].mean())\n",
        "  rmse_list.append(model_rmse)\n",
        "  \n",
        "  # Compute Coverage:\n",
        "  rank, cov = coverage(\n",
        "      train_full[['review_id','user_id','business_id','rating']], \n",
        "      test_df_cat[['review_id','user_id','business_id','rating','prediction']])\n",
        "  coverage_list.append(cov)\n",
        "\n",
        "  # Compute Spearman: REPLACE THIS WITH NEW METRIC\n",
        "\n",
        "  # Clean up:\n",
        "  del test_df, test_df_cat, rank\n",
        "\n",
        "# Build your dataframe for the report and export to CSV:\n",
        "table_1 = pd.DataFrame({'Model': model_list, 'RMSE': rmse_list, 'Coverage': coverage_list})\n",
        "upload_csv_to_drive(\"12pKbs8ptxpPaqaMmArivSqXQ58uv3iV0\", table_1, \"table_1.csv\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on bias_baseline\n",
            "Working on cf_baseline\n",
            "Working on deep_learning_m1f1\n",
            "Working on deep_learning_m1f2\n",
            "Working on deep_learning_m2f1\n",
            "Working on deep_learning_m2f2\n",
            "Upload complete for:  table_1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjrx2-29km4e",
        "colab_type": "code",
        "outputId": "6450a740-75a6-4a58-ba09-ea98fa7d9d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "table_1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>Coverage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bias_baseline</td>\n",
              "      <td>1.391587</td>\n",
              "      <td>48.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cf_baseline</td>\n",
              "      <td>1.336046</td>\n",
              "      <td>49.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>deep_learning_m1f1</td>\n",
              "      <td>1.936393</td>\n",
              "      <td>55.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>deep_learning_m1f2</td>\n",
              "      <td>1.932867</td>\n",
              "      <td>55.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>deep_learning_m2f1</td>\n",
              "      <td>1.514599</td>\n",
              "      <td>41.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>deep_learning_m2f2</td>\n",
              "      <td>1.514133</td>\n",
              "      <td>41.53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model      RMSE  Coverage\n",
              "0       bias_baseline  1.391587     48.00\n",
              "1         cf_baseline  1.336046     49.96\n",
              "2  deep_learning_m1f1  1.936393     55.40\n",
              "3  deep_learning_m1f2  1.932867     55.43\n",
              "4  deep_learning_m2f1  1.514599     41.64\n",
              "5  deep_learning_m2f2  1.514133     41.53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTZBEtBKkoyR",
        "colab_type": "text"
      },
      "source": [
        "## Build Table 2/3 for final report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seWEjxTPhgGj",
        "colab_type": "text"
      },
      "source": [
        "#### Methods for Metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWDiKzqfhkLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_RMSE_by_group(input_mat, model_name, metric_name, grouper):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  1. Ratings matrix with columns 'rating' and 'prediction'\n",
        "  2. A column by which to group your metrics (any categorical column in 'categorization' matrix)\n",
        "  3. A model name (e.g. 'CF_Baseline')\n",
        "  4. A metric name (e.g. 'RMSE')\n",
        "  Output: A long-form dataframe reporting RMSE by model, metric, and variable group.\n",
        "  \"\"\"\n",
        "  # Calculate RMSE\n",
        "  input_mat['squared_error'] = (input_mat['rating'] - input_mat['prediction'])**2\n",
        "  test_df_grouped = pd.DataFrame(input_mat.groupby(grouper)['squared_error'].agg('mean')).reset_index()\n",
        "  test_df_grouped['metric_value'] = np.sqrt(test_df_grouped['squared_error'])\n",
        "  # Append metric and model columns\n",
        "  test_df_grouped = pd.merge(pd.DataFrame({'metric': [metric_name] * len(test_df_grouped)}), test_df_grouped, left_index=True, right_index=True)\n",
        "  test_df_grouped = pd.merge(pd.DataFrame({'model': [model_name] * len(test_df_grouped)}), test_df_grouped, left_index=True, right_index=True)\n",
        "  test_df_grouped = test_df_grouped.drop(['squared_error'], axis=1)\n",
        "  \n",
        "  return test_df_grouped\n",
        "\n",
        "def calculate_coverage_by_group(input_mat, model_name, metric_name, grouper):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  1. As input, must use the output of the method \"ranking\" defined above.\n",
        "  2. A column by which to group your metrics (any categorical column in 'categorization' matrix)\n",
        "  3. A model name (e.g. 'CF_Baseline')\n",
        "  4. A metric name (e.g. 'RMSE')\n",
        "  Output: A long-form dataframe reporting coverage by model, metric, and variable group.\n",
        "  \"\"\"\n",
        "  # Join it to categorization to get categories for grouping:\n",
        "  model_ranking_cat = pd.merge(input_mat, categorization, on='review_id', how='inner')\n",
        "\n",
        "  # Calculate coverage:\n",
        "  diff = (model_ranking_cat['true_rank'] - model_ranking_cat['pred_rank']) / model_ranking_cat['number_reviews']\n",
        "  model_ranking_cat['metric_value'] = np.where(np.abs(diff)<0.25, 1.0,0.0)  #1: good recom. 0: bad recom.\n",
        "  test_df_grouped = pd.DataFrame(model_ranking_cat.groupby(grouper)['metric_value'].agg('mean')).reset_index()\n",
        "  test_df_grouped['metric_value'] = round(100.0 * test_df_grouped['metric_value'], 2)\n",
        "\n",
        "  # Append metric and model columns:\n",
        "  test_df_grouped = pd.merge(pd.DataFrame({'metric': [metric_name] * len(test_df_grouped)}), test_df_grouped, left_index=True, right_index=True)\n",
        "  test_df_grouped = pd.merge(pd.DataFrame({'model': [model_name] * len(test_df_grouped)}), test_df_grouped, left_index=True, right_index=True)\n",
        "  \n",
        "  return test_df_grouped "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC0eWaFQkvPJ",
        "colab_type": "code",
        "outputId": "5f14c1f6-5dc1-41a0-c025-bc90e0642730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# This loop will calculate all metrics for all models and save it to a dataframe:\n",
        "\n",
        "grouper_values = ['is_open','business_popularity_bin','user_activity_bin'] # do a subset of cities later\n",
        "\n",
        "for grouper_value in grouper_values:\n",
        "  table_2 = pd.DataFrame()\n",
        "\n",
        "  for row in dataframes:\n",
        "    print(\"Working on\", row)\n",
        "    model_list.append(row)\n",
        "    \n",
        "    # Get the necessary DFs: \n",
        "      # 1) test results (test_df), \n",
        "      # 2) augmented test results with categories (test_df_cat), \n",
        "    test_df = dataframes[row]\n",
        "    test_df_cat = pd.merge(test_df, categorization, on='review_id', how='inner')\n",
        "    \n",
        "    # Compute RMSE by grouping (TODO: iterate over these groupings):\n",
        "    table_2 = table_2.append(calculate_RMSE_by_group(test_df_cat, row, 'RMSE', grouper_value))\n",
        "    \n",
        "    # Compute Coverage by grouping:\n",
        "    # Take the ranking (this is the precursor to coverage): \n",
        "    model_ranking = ranking(\n",
        "      train_full[['review_id','user_id','business_id','rating']], \n",
        "      test_df_cat[['review_id','user_id','business_id','rating','prediction']])\n",
        "    table_2 = table_2.append(calculate_coverage_by_group(model_ranking, row, 'coverage', grouper_value))\n",
        "\n",
        "    # Compute Spearman: REPLACE THIS WITH NEW METRIC\n",
        "    # Clean up:\n",
        "    del test_df, test_df_cat, model_ranking\n",
        "\n",
        "  # Build your dataframe for the report:\n",
        "  table_2 = table_2.pivot_table(\n",
        "    values = 'metric_value',\n",
        "    index = ['model', 'metric'],\n",
        "    columns = grouper_value).reset_index()\n",
        "\n",
        "  # Upload as named CSV\n",
        "  file_name = grouper_value + '_table_2.csv'\n",
        "  upload_csv_to_drive('12pKbs8ptxpPaqaMmArivSqXQ58uv3iV0', table_2, file_name)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working on bias_baseline\n",
            "Working on cf_baseline\n",
            "Working on deep_learning_m1f1\n",
            "Working on deep_learning_m1f2\n",
            "Working on deep_learning_m2f1\n",
            "Working on deep_learning_m2f2\n",
            "Upload complete for:  is_open_table_2.csv\n",
            "Working on bias_baseline\n",
            "Working on cf_baseline\n",
            "Working on deep_learning_m1f1\n",
            "Working on deep_learning_m1f2\n",
            "Working on deep_learning_m2f1\n",
            "Working on deep_learning_m2f2\n",
            "Upload complete for:  business_popularity_bin_table_2.csv\n",
            "Working on bias_baseline\n",
            "Working on cf_baseline\n",
            "Working on deep_learning_m1f1\n",
            "Working on deep_learning_m1f2\n",
            "Working on deep_learning_m2f1\n",
            "Working on deep_learning_m2f2\n",
            "Upload complete for:  user_activity_bin_table_2.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp0ngBZOkoP9",
        "colab_type": "code",
        "outputId": "adc0ca5a-77c4-4d8d-a3d2-38784892d3a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "table_2"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>user_activity_bin</th>\n",
              "      <th>model</th>\n",
              "      <th>metric</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>medium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bias_baseline</td>\n",
              "      <td>RMSE</td>\n",
              "      <td>1.282249</td>\n",
              "      <td>1.437495</td>\n",
              "      <td>1.356632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bias_baseline</td>\n",
              "      <td>coverage</td>\n",
              "      <td>51.880000</td>\n",
              "      <td>47.640000</td>\n",
              "      <td>46.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cf_baseline</td>\n",
              "      <td>RMSE</td>\n",
              "      <td>1.272532</td>\n",
              "      <td>1.357752</td>\n",
              "      <td>1.327999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cf_baseline</td>\n",
              "      <td>coverage</td>\n",
              "      <td>52.110000</td>\n",
              "      <td>50.250000</td>\n",
              "      <td>47.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>deep_learning_m1f1</td>\n",
              "      <td>RMSE</td>\n",
              "      <td>1.794966</td>\n",
              "      <td>1.963291</td>\n",
              "      <td>1.964366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>deep_learning_m1f1</td>\n",
              "      <td>coverage</td>\n",
              "      <td>49.230000</td>\n",
              "      <td>57.830000</td>\n",
              "      <td>54.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>deep_learning_m1f2</td>\n",
              "      <td>RMSE</td>\n",
              "      <td>1.787742</td>\n",
              "      <td>1.962020</td>\n",
              "      <td>1.958074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>deep_learning_m1f2</td>\n",
              "      <td>coverage</td>\n",
              "      <td>49.200000</td>\n",
              "      <td>57.860000</td>\n",
              "      <td>54.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>deep_learning_m2f1</td>\n",
              "      <td>RMSE</td>\n",
              "      <td>1.443523</td>\n",
              "      <td>1.532555</td>\n",
              "      <td>1.519637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>deep_learning_m2f1</td>\n",
              "      <td>coverage</td>\n",
              "      <td>39.570000</td>\n",
              "      <td>43.450000</td>\n",
              "      <td>39.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>deep_learning_m2f2</td>\n",
              "      <td>RMSE</td>\n",
              "      <td>1.442843</td>\n",
              "      <td>1.532263</td>\n",
              "      <td>1.518922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>deep_learning_m2f2</td>\n",
              "      <td>coverage</td>\n",
              "      <td>39.490000</td>\n",
              "      <td>43.380000</td>\n",
              "      <td>38.800000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "user_activity_bin               model    metric  ...        low     medium\n",
              "0                       bias_baseline      RMSE  ...   1.437495   1.356632\n",
              "1                       bias_baseline  coverage  ...  47.640000  46.310000\n",
              "2                         cf_baseline      RMSE  ...   1.357752   1.327999\n",
              "3                         cf_baseline  coverage  ...  50.250000  47.930000\n",
              "4                  deep_learning_m1f1      RMSE  ...   1.963291   1.964366\n",
              "5                  deep_learning_m1f1  coverage  ...  57.830000  54.050000\n",
              "6                  deep_learning_m1f2      RMSE  ...   1.962020   1.958074\n",
              "7                  deep_learning_m1f2  coverage  ...  57.860000  54.100000\n",
              "8                  deep_learning_m2f1      RMSE  ...   1.532555   1.519637\n",
              "9                  deep_learning_m2f1  coverage  ...  43.450000  39.010000\n",
              "10                 deep_learning_m2f2      RMSE  ...   1.532263   1.518922\n",
              "11                 deep_learning_m2f2  coverage  ...  43.380000  38.800000\n",
              "\n",
              "[12 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejw1uj24kujb",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUw6PrLHH4eM",
        "colab_type": "text"
      },
      "source": [
        "# ----------------------------------------------------\n",
        "## Practice, ignore:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8IekADQH3fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_df = dataframes['cf_baseline']\n",
        "# test_df_cat = pd.merge(test_df, categorization, on='review_id', how='inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jamNLzfd4cV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(test_df.shape)\n",
        "# print(train_full.shape)\n",
        "# print(categorization.shape)\n",
        "# test_df_cat.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2wDoq75rqdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Coverage\n",
        "# def calculate_RMSE_by_group(input_mat, model_name, metric_name, grouper):\n",
        "#   \"\"\"\n",
        "#   Inputs:\n",
        "#   1. Ratings matrix with columns 'rating' and 'prediction'\n",
        "#   2. A column by which to group your metrics (any categorical column in 'categorization' matrix)\n",
        "#   3. A model name (e.g. 'CF_Baseline')\n",
        "#   4. A metric name (e.g. 'RMSE')\n",
        "#   \"\"\"\n",
        "#   # Calculate RMSE\n",
        "#   input_mat['squared_error'] = (input_mat['rating'] - input_mat['prediction'])**2\n",
        "#   test_df_grouped = pd.DataFrame(input_mat.groupby(grouper)['squared_error'].agg('mean')).reset_index()\n",
        "#   test_df_grouped['metric_value'] = np.sqrt(test_df_grouped['squared_error'])\n",
        "#   # Append metric and model columns\n",
        "#   test_df_grouped = pd.merge(pd.DataFrame({'metric': [metric_name] * len(test_df_grouped)}), test_df_grouped, left_index=True, right_index=True)\n",
        "#   test_df_grouped = pd.merge(pd.DataFrame({'model': [model_name] * len(test_df_grouped)}), test_df_grouped, left_index=True, right_index=True)\n",
        "#   test_df_grouped = test_df_grouped.drop(['squared_error'], axis=1)\n",
        "  \n",
        "#   return test_df_grouped\n",
        "\n",
        "\n",
        "# # Take the ranking (this is the precursor to coverage): \n",
        "# model_ranking = ranking(\n",
        "#     train_full[['review_id','user_id','business_id','rating']], \n",
        "#     test_df_cat[['review_id','user_id','business_id','rating','prediction']])\n",
        "\n",
        "# calculate_coverage_by_group(model_ranking, 'some_model', 'coverage', 'user_activity_bin')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK6zQ0tN5YGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_df_grouped"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EYBV0OxmjK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# csv_files = {\n",
        "#   'train_set_new': '1-1vfc5jxrCggpVYDkf8Z2rVLjIIOh6bu'\n",
        "# }\n",
        "\n",
        "# dfs = {}\n",
        "\n",
        "# for key, value in csv_files.items():\n",
        "#   csv_name = key + '.csv'\n",
        "#   downloaded = drive.CreateFile({'id': value})\n",
        "#   downloaded.GetContentFile(csv_name)\n",
        "#   dfs[key] = pd.read_csv(csv_name, low_memory=False)\n",
        "#   print(\"Done with: \", key)\n",
        "\n",
        "# train_full = dfs['train_set_new']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJtEIvPFlGnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# full_df_cat.user_id.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDdZGoqQQTKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Try ranking: \n",
        "# r = ranking(\n",
        "#     train_full[['review_id','user_id','business_id','rating']], \n",
        "#     test_df_cat[['review_id','user_id','business_id','rating','prediction']])\n",
        "\n",
        "# r.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBtrj1RRA4E7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Try coverage:\n",
        "# rank, cov = coverage(\n",
        "#     train_full[['review_id','user_id','business_id','rating']], \n",
        "#     test_df_cat[['review_id','user_id','business_id','rating','prediction']])\n",
        "\n",
        "# cov # 1.24 doesn't seem right; it should be between 0-1, right?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFSPe8blcayX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # User rank to test spearman:\n",
        "# print(rank.shape)\n",
        "# print(len(rank['user_id'].unique()))\n",
        "# rank.head()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}